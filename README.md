# AWS Serverless Project Documentation

## Table of Contents
1. [Project Overview](#project-overview)
2. [Repositories Breakdown](#repositories-breakdown)
    - [S3 Storage](#s3-storage)
    - [DynamoDB](#dynamodb)
    - [API Gateway](#api-gateway)
    - [Lambda (API Invocation)](#lambda-api-invocation)
    - [Lambda (Scheduled Task)](#lambda-scheduled-task)
3. [CI/CD Pipeline](#ci-cd-pipeline)
4. [Infrastructure as Code (IaC)](#infrastructure-as-code-iac)
5. [Deployment Instructions](#deployment-instructions)
6. [Technical Choices](#technical-choices)

---

## Project Overview

This project demonstrates how to build a serverless application on AWS using a combination of AWS services such as S3, DynamoDB, API Gateway, Lambda, and EventBridge. The primary goal is to create an endpoint where data can be sent in JSON format and stored in DynamoDB. Additionally, a scheduled Lambda function generates a summary of the data and stores it in an S3 bucket on a weekly basis.

Each service is managed using Infrastructure as Code (IaC) with AWS CDK, SAM, and CloudFormation. The project also incorporates CI/CD automation using GitHub Actions for continuous deployment.

---

## Repositories Breakdown

### 1. S3 Storage
**Repository**: [aws-s3-terraform](https://github.com/lucassimoesmaistro/aws-s3-terraform)

**Description**: This repository handles the creation of an S3 bucket using Terraform. The S3 bucket is used to store the summary file generated by the scheduled Lambda function. The file contains the total number of items stored in the DynamoDB table.

- **Bucket Name**: Stores summary files.
- **File Format**: The summary is saved as a `.txt` file with a timestamp in the file name, e.g., `summary-2024-09-24.txt`.

---

### 2. DynamoDB
**Repository**: [aws-dynamodb-cloudformation](https://github.com/lucassimoesmaistro/aws-dynamodb-cloudformation)

**Description**: This repository provisions a DynamoDB table using AWS CloudFormation. It is the main datastore for this project, where the JSON data sent via the API Gateway is stored.

- **Table Name**: `NamePerCity`
- **Primary Key**: 
  - Hash Key: `City`
  - Range Key: `PersonName`
- **Task**: Store and retrieve data related to names and cities.

---

### 3. API Gateway
**Repository**: [aws-apigateway-cdk-python](https://github.com/lucassimoesmaistro/aws-apigateway-cdk-python)

**Description**: This repository provisions an API Gateway endpoint using AWS CDK with Python. The API provides an endpoint where JSON data can be submitted, which will then trigger a Lambda function to store the data in the DynamoDB table.

- **Endpoint**: `/name`
- **Integration**: Invokes a Lambda function to persist data in DynamoDB.
- **Input Format**: JSON structure, e.g., `{"City": "Berlin", "PersonName": "John Doe"}`.

---

### 4. Lambda (API Invocation)
**Repository**: [aws-lambda-sam](https://github.com/lucassimoesmaistro/aws-lambda-sam)

**Description**: This repository provisions the Lambda function that is triggered by the API Gateway when data is submitted. The Lambda function stores the incoming JSON data into the DynamoDB table.

- **Language**: Python
- **Trigger**: API Gateway
- **Task**: Processes the API request and writes data to DynamoDB.

---

### 5. Lambda (Scheduled Task)
**Repository**: [aws-lambda-eventbridge-sam](https://github.com/lucassimoesmaistro/aws-lambda-eventbridge-sam)

**Description**: This repository provisions a Lambda function using AWS SAM, which is triggered by EventBridge on a weekly schedule. The function counts the total number of items in the DynamoDB table and writes a summary file to the S3 bucket.

- **Language**: Python
- **Trigger**: EventBridge (weekly schedule)
- **Task**: Generates a summary of the data in DynamoDB and saves it to S3.

---

## CI/CD Pipeline

The CI/CD pipeline is implemented using GitHub Actions for continuous integration and deployment across all repositories. The following steps are automated for each repository:

1. **Code Commit**: Developer commits code to the repository.
2. **GitHub Actions Workflow**: A GitHub Actions workflow is triggered on each commit or pull request to run automated tests, check formatting, and ensure that the code is ready for deployment.
3. **Build and Deploy**: If the code passes the tests, it is automatically deployed to AWS using the appropriate IaC tool (Terraform, CloudFormation, SAM, or CDK).
4. **Verification**: Post-deployment, the infrastructure is validated, and logs are checked for any errors.

The GitHub Actions pipeline uses OpenID Connect (OIDC) to assume roles within AWS securely without needing long-term credentials.

---

## Infrastructure as Code (IaC)

All resources in this project are provisioned using Infrastructure as Code (IaC) tools to ensure consistency and repeatability. The specific IaC tools used for each repository are:

- **Terraform**: S3 bucket creation.
- **CloudFormation**: DynamoDB table creation.
- **AWS CDK (Python)**: API Gateway and its related Lambda function.
- **AWS SAM**: Lambda function for both API invocation and scheduled task with EventBridge.

Using IaC, we ensure that the infrastructure can be deployed and managed programmatically with version control, improving maintainability and collaboration.

---

## Project Deployment Guide

This guide explains how to deploy the components of the project using GitHub Actions and Infrastructure as Code tools.

### Deployment Instructions

The deployment process for all resources (S3 bucket, DynamoDB, API Gateway, Lambdas) is automated using GitHub Actions. The steps to execute the deployment are as follows:

1. **Create a feature branch:**
   
   To begin, create a new feature branch from the `develop` branch:
   
   ```bash
   git checkout develop
   git checkout -b feature/my-feature

2. **Push the feature branch:**
   
   Push your feature branch to the remote repository:
   
   ```bash
   git push origin feature/my-feature

3. **Open a Pull Request:**

Open a Pull Request (PR) from your feature branch into the develop branch using the GitHub interface. When the PR is created, the GitHub Actions workflow will automatically be triggered to deploy the infrastructure.

4. **Monitor the Workflow:**

The GitHub Actions workflow will automatically provision the following resources:

- **S3 bucket** to store the summary files
- **DynamoDB table** to persist the incoming data
- **API Gateway** to expose the `/name` endpoint
- **Lambda functions** triggered by the API Gateway and by EventBridge (scheduled)

You can monitor the progress of the workflow in the "Actions" tab of your GitHub repository. Once the workflow completes successfully, the infrastructure will be deployed in your AWS account.


---

## Technical Choices

### Why AWS?
AWS was chosen for its extensive serverless offerings, such as Lambda, DynamoDB, and S3, which allow for scalable and cost-effective solutions that fit within the Free Tier.


### Why Terraform and CloudFormation?
These IaC tools provide flexibility in managing infrastructure. Terraform is used for S3 due to its multi-cloud capabilities, while CloudFormation is AWS-native and fits well with DynamoDB provisioning.

### Why CDK and SAM?
AWS CDK with Python offers a programmatic way to define infrastructure, which is easier to manage for complex setups like API Gateway. AWS SAM is excellent for Lambda-based applications, offering a simplified way to manage serverless functions and event-driven architectures.

### Why GitHub Actions?
GitHub Actions allows for automated deployment pipelines, reducing manual intervention and ensuring that the code is always deployed in a consistent, secure manner using OIDC for role assumption.

